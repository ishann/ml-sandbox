{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Makemore\n",
    "\n",
    "A character-level language model that is learnt in an auto-regressive fashion.    \n",
    "\n",
    "Becoming a backprop ninja, swole doge style."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yes you should understand backprop.\n",
    "\n",
    "> The problem with Backpropagation is that it is a **leaky abstraction**.\n",
    "\n",
    "It is easy to fall into the trap of auto-differentiating your way through a lifetime of engineering Machine Learning systems - believing that you can simply stack arbitrary layers together and backprop will “magically make them work” on your data.\n",
    "\n",
    "A few common errors that are difficult to debug:\n",
    "\n",
    "* Vanishing gradients on sigmoids\n",
    "  * If we are sloppy with the weight initialization or data preprocessing, the sigmoid can “saturate” and entirely stop learning — the training loss will be flat and refuse to go down. This is because the gradients of the sigmoid function are very small when the input is large or small\n",
    "  * If the weight matrix is initialized too large, the output of the matrix multiply could have a very large range, which will make all elements in the output (say, `z`) almost binary: either 1 or 0. Then, the gradient, `z*(1-z)`, will in both cases become zero (“vanish”), making the gradient for W zero. The rest of the backward pass will come out all zero from this point on due to multiplication in the chain rule.\n",
    "  * The sigmoid local gradient (`z*(1-z)`) achieves a maximum at 0.25, when z = 0.5. Thus, every time the gradient flows through a sigmoid, its magnitude diminishes by one quarter (or more). Thus, stacking MLP layers with sigmoids can make the lower network layers train much slower than the higher ones.\n",
    "\n",
    "* Dying ReLU\n",
    "  * If a neuron gets clamped to zero in the forward pass, i.e., it doesn’t “fire”, its weights will get zero gradient.\n",
    "  * This can lead to the “dead ReLU” problem: if a ReLU neuron is unfortunately initialized such that it never fires, or if a neuron’s weights get knocked off with a large update during training, then this neuron will remain permanently dead.\n",
    "  * Neurons can also die during training, usually as a symptom of aggressive learning rates.\n",
    "\n",
    "* Exploding gradients in RNNs\n",
    "  * When an RNN is unrolled for `T` time steps, the gradient signal going backwards in time through all the hidden states is multiplied by the same matrix (the recurrence matrix).\n",
    "  * `a*b*b*b*b*b*b…` either goes to zero if `|b|<1` or explodes to infinity if `|b|>1`. In the backward pass of an RNN, `b` is a matrix but we can reason similarly based on its largest eigenvalue.\n",
    "  * TL;DR: When using RNNs, be careful about having to do gradient clipping.\n",
    "\n",
    "* Spotted in the Wild: DQN Clipping\n",
    "  * Discussion of a public implementation = [link](https://github.com/devsisters/DQN-tensorflow/issues/16).\n",
    "  * Let `target_q_t = [reward * \\gamma \\argmax_a Q(s’,a)]` (max reward) and `q_acted=Q(s,a)` (action taken). The implementation subtracts the two and minimizes the MSE over this `delta`.\n",
    "  * The problem lies in the attempt to be robust to outliers: If `delta` is too large, they clip it, introducing a major bug wrt the backward pass.\n",
    "  * The clipping sets the local gradient to zero outside of the clipping range. Thus, the gradient becomes exactly zero during backprop.\n",
    "  * The implementation clips the raw `Q` delta, when they are likely trying to clip the gradient for added robustness.\n",
    "  * In that case the correct thing to do is to use the Huber loss in place of `MSE`.\n",
    "\n",
    "`Conclusion`: Backprop is a leaky abstraction. It is important to understand the mechanics of backpropagation, and to be able to debug it when things go wrong.\n",
    "\n",
    "\n",
    "**`TODO`**: [CS231n Backpropagation Lecture.](https://www.youtube.com/watch?v=i94OvYb6noo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#import seaborn as sns\n",
    "#sns.set()\n",
    "\n",
    "SEED = 2147483647"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A few words: ['emma', 'olivia', 'ava', 'isabella', 'sophia']\n",
      "Length of words: 32033\n"
     ]
    }
   ],
   "source": [
    "# read in all the words\n",
    "words = open('./data/names.txt', 'r').read().splitlines()\n",
    "print(f\"A few words: {words[:5]}\")\n",
    "print(f\"Length of words: {len(words)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "# Build the vocabulary of characters and mappings to/from integers.\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "vocab_size = len(itos)\n",
    "print(itos)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 3]) torch.Size([182625])\n",
      "torch.Size([22655, 3]) torch.Size([22655])\n",
      "torch.Size([22866, 3]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
    "\n",
    "def build_dataset(words):  \n",
    "  X, Y = [], []\n",
    "  \n",
    "  for w in words:\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "      ix = stoi[ch]\n",
    "      X.append(context)\n",
    "      Y.append(ix)\n",
    "      context = context[1:] + [ix] # crop and append\n",
    "\n",
    "  X = torch.tensor(X)\n",
    "  Y = torch.tensor(Y)\n",
    "  print(X.shape, Y.shape)\n",
    "  return X, Y\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "Xtr,  Ytr  = build_dataset(words[:n1])     # 80%\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])   # 10%\n",
    "Xte,  Yte  = build_dataset(words[n2:])     # 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function we will use later when comparing manual gradients to PyTorch gradients\n",
    "def cmp(s, dt, t):\n",
    "  ex = torch.all(dt == t.grad).item()\n",
    "  app = torch.allclose(dt, t.grad)\n",
    "  maxdiff = (dt - t.grad).abs().max().item()\n",
    "  print(f'{s:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {maxdiff}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4137\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 64 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "C  = torch.randn((vocab_size, n_embd),            generator=g)\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)\n",
    "b1 = torch.randn(n_hidden,                        generator=g) * 0.1 # using b1 just for fun, it's useless because of BN\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size),          generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size,                      generator=g) * 0.1\n",
    "# BatchNorm parameters\n",
    "bngain = torch.randn((1, n_hidden))*0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden))*0.1\n",
    "\n",
    "# Note: I am initializating many of these parameters in non-standard ways\n",
    "# because sometimes initializating with e.g. all zeros could mask an incorrect\n",
    "# implementation of the backward pass.\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "  p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n = batch_size # a shorter variable also, for convenience\n",
    "# construct a minibatch\n",
    "ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detailed Forward and Backward passes, to allow for manual back-propagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.3417, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward pass, \"chunkated\" into smaller steps that are possible to backward one at a time\n",
    "\n",
    "emb = C[Xb] # embed the characters into vectors\n",
    "embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "# Linear layer 1\n",
    "hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "# BatchNorm layer\n",
    "bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n",
    "bndiff = hprebn - bnmeani\n",
    "bndiff2 = bndiff**2\n",
    "bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n",
    "bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "bnraw = bndiff * bnvar_inv\n",
    "hpreact = bngain * bnraw + bnbias\n",
    "# Non-linearity\n",
    "h = torch.tanh(hpreact) # hidden layer\n",
    "# Linear layer 2\n",
    "logits = h @ W2 + b2 # output layer\n",
    "# cross entropy loss (same as F.cross_entropy(logits, Yb))\n",
    "logit_maxes = logits.max(1, keepdim=True).values\n",
    "norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
    "counts = norm_logits.exp()\n",
    "counts_sum = counts.sum(1, keepdims=True)\n",
    "counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
    "probs = counts * counts_sum_inv\n",
    "logprobs = probs.log()\n",
    "loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "# PyTorch backward pass\n",
    "for p in parameters:\n",
    "  p.grad = None\n",
    "for t in [logprobs, probs, counts, counts_sum, counts_sum_inv, # afaik there is no cleaner way\n",
    "          norm_logits, logit_maxes, logits, h, hpreact, bnraw,\n",
    "         bnvar_inv, bnvar, bndiff2, bndiff, hprebn, bnmeani,\n",
    "         embcat, emb]:\n",
    "  t.retain_grad()\n",
    "loss.backward()\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`NOTE`: Unlike Andrej's suggestion, I did not work through computing the gradients on my own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprobs        | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "probs           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts_sum_inv  | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts_sum      | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "norm_logits     | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "logit_maxes     | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "logits          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "h               | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "W2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "b2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "hpreact         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bngain          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnbias          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnraw           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnvar_inv       | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnvar           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bndiff2         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bndiff          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnmeani         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "hprebn          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "embcat          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "W1              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "b1              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "emb             | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "C               | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1: backprop through the whole thing manually, \n",
    "# backpropagating through exactly all of the variables \n",
    "# as they are defined in the forward pass above, one by one\n",
    "\n",
    "dlogprobs = torch.zeros_like(logprobs)\n",
    "dlogprobs[range(n), Yb] = -1.0/n\n",
    "dprobs = (1.0 / probs) * dlogprobs\n",
    "dcounts_sum_inv = (counts * dprobs).sum(1, keepdim=True)\n",
    "dcounts = counts_sum_inv * dprobs\n",
    "dcounts_sum = (-counts_sum**-2) * dcounts_sum_inv\n",
    "dcounts += torch.ones_like(counts) * dcounts_sum\n",
    "dnorm_logits = counts * dcounts\n",
    "dlogits = dnorm_logits.clone()\n",
    "dlogit_maxes = (-dnorm_logits).sum(1, keepdim=True)\n",
    "dlogits += F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]) * dlogit_maxes\n",
    "dh = dlogits @ W2.T\n",
    "dW2 = h.T @ dlogits\n",
    "db2 = dlogits.sum(0)\n",
    "dhpreact = (1.0 - h**2) * dh\n",
    "dbngain = (bnraw * dhpreact).sum(0, keepdim=True)\n",
    "dbnraw = bngain * dhpreact\n",
    "dbnbias = dhpreact.sum(0, keepdim=True)\n",
    "dbndiff = bnvar_inv * dbnraw\n",
    "dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True)\n",
    "dbnvar = (-0.5*(bnvar + 1e-5)**-1.5) * dbnvar_inv\n",
    "dbndiff2 = (1.0/(n-1))*torch.ones_like(bndiff2) * dbnvar\n",
    "dbndiff += (2*bndiff) * dbndiff2\n",
    "dhprebn = dbndiff.clone()\n",
    "dbnmeani = (-dbndiff).sum(0)\n",
    "dhprebn += 1.0/n * (torch.ones_like(hprebn) * dbnmeani)\n",
    "dembcat = dhprebn @ W1.T\n",
    "dW1 = embcat.T @ dhprebn\n",
    "db1 = dhprebn.sum(0)\n",
    "demb = dembcat.view(emb.shape)\n",
    "dC = torch.zeros_like(C)\n",
    "for k in range(Xb.shape[0]):\n",
    "  for j in range(Xb.shape[1]):\n",
    "    ix = Xb[k,j]\n",
    "    dC[ix] += demb[k,j]\n",
    "    \n",
    "cmp('logprobs', dlogprobs, logprobs)\n",
    "cmp('probs', dprobs, probs)\n",
    "cmp('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
    "cmp('counts_sum', dcounts_sum, counts_sum)\n",
    "cmp('counts', dcounts, counts)\n",
    "cmp('norm_logits', dnorm_logits, norm_logits)\n",
    "cmp('logit_maxes', dlogit_maxes, logit_maxes)\n",
    "cmp('logits', dlogits, logits)\n",
    "cmp('h', dh, h)\n",
    "cmp('W2', dW2, W2)\n",
    "cmp('b2', db2, b2)\n",
    "cmp('hpreact', dhpreact, hpreact)\n",
    "cmp('bngain', dbngain, bngain)\n",
    "cmp('bnbias', dbnbias, bnbias)\n",
    "cmp('bnraw', dbnraw, bnraw)\n",
    "cmp('bnvar_inv', dbnvar_inv, bnvar_inv)\n",
    "cmp('bnvar', dbnvar, bnvar)\n",
    "cmp('bndiff2', dbndiff2, bndiff2)\n",
    "cmp('bndiff', dbndiff, bndiff)\n",
    "cmp('bnmeani', dbnmeani, bnmeani)\n",
    "cmp('hprebn', dhprebn, hprebn)\n",
    "cmp('embcat', dembcat, embcat)\n",
    "cmp('W1', dW1, W1)\n",
    "cmp('b1', db1, b1)\n",
    "cmp('emb', demb, emb)\n",
    "cmp('C', dC, C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bessel's Correction\n",
    "\n",
    "Is generally not a problem for large N, but we are dealing with mini-batches in the BatchNorm layer, so this becomes a significant issue.\n",
    "\n",
    "$\\sigma^2=\\frac{\\sum(x-\\mu)^2}{N}$\n",
    "\n",
    "$s_{\\text{biased}}^2=\\frac{\\sum(x-\\bar{x})^2}{n}$\n",
    "\n",
    "Since the sample mean ($\\bar{x}$) is closer to the $x_i$, than the population mean ($\\mu$), the sample variance is an under-estimation of the population variance:    \n",
    "\n",
    "$(x-\\bar{x}) < (x-\\mu)$\n",
    "$\\implies \\text{E}\\left[ (x-\\bar{x}^2) \\right] < \\text{E}\\left[ (x-\\mu)^2 \\right]$\n",
    "$\\implies s^2_{\\text{biased}}< \\mu^2$\n",
    "$\\implies s^2_{\\text{biased}} = F_c \\cdot \\mu^2$    \n",
    "\n",
    "This $F_c$ is the correction factor and needs to be estimated.\n",
    "\n",
    "$\\text{E}[s^2_{\\text{biased}}]= \\text{E}\\left[ \\frac{\\sum(x-\\bar{x})^2}{n} \\right] = \\text{E}\\left[ \\frac{1}{n}\\sum_{i=1}^n [(x_i-\\mu)-(\\bar{x_i}-\\mu)]^2 \\right]$\n",
    "\n",
    "Expanding the above expression results in the correction factor:    \n",
    "$F_c=\\frac{n-1}{n} \\implies \\text{E}[s^2_{\\text{biased}}] = \\left( \\frac{n-1}{n} \\right) \\sigma^2$\n",
    "\n",
    "Reference: [Bessel's Correction](https://math.oxford.emory.edu/site/math117/besselCorrection/#:~:text=To%20intuitively%20see%20this%2C%20consider,0%20is%20clearly%20an%20underestimate.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:3.3417\n",
      "loss_fast:3.3417\n",
      "diff:-2.384185791015625e-07\n"
     ]
    }
   ],
   "source": [
    "# Exercise 2: backprop through cross_entropy but all in one go\n",
    "# to complete this challenge look at the mathematical expression of the loss,\n",
    "# take the derivative, simplify the expression, and just write it out\n",
    "\n",
    "# forward pass\n",
    "\n",
    "# before:\n",
    "# logit_maxes = logits.max(1, keepdim=True).values\n",
    "# norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
    "# counts = norm_logits.exp()\n",
    "# counts_sum = counts.sum(1, keepdims=True)\n",
    "# counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
    "# probs = counts * counts_sum_inv\n",
    "# logprobs = probs.log()\n",
    "# loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "# now:\n",
    "loss_fast = F.cross_entropy(logits, Yb)\n",
    "print(f\"loss:{loss.item():.4f}\\nloss_fast:{loss_fast.item():.4f}\\ndiff:{(loss_fast - loss).item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits          | exact: False | approximate: True  | maxdiff: 5.587935447692871e-09\n"
     ]
    }
   ],
   "source": [
    "# backward pass\n",
    "dlogits = F.softmax(logits, 1)\n",
    "dlogits[range(n), Yb] -= 1\n",
    "dlogits /= n\n",
    "\n",
    "cmp('logits', dlogits, logits) # I can only get approximate to be true, my maxdiff is 6e-9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This visualization intuitively shows how the pulling up (of the correct class) and the pushing down (of the incorrect class) happens in each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9a4d8c3610>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(dlogits.detach(), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max diff: 4.76837158203125e-07\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3: backprop through batchnorm but all in one go\n",
    "# to complete this challenge look at the mathematical expression of the output of batchnorm,\n",
    "# take the derivative w.r.t. its input, simplify the expression, and just write it out\n",
    "\n",
    "# forward pass\n",
    "\n",
    "# before:\n",
    "# bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n",
    "# bndiff = hprebn - bnmeani\n",
    "# bndiff2 = bndiff**2\n",
    "# bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n",
    "# bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "# bnraw = bndiff * bnvar_inv\n",
    "# hpreact = bngain * bnraw + bnbias\n",
    "\n",
    "# now:\n",
    "hpreact_fast = bngain * (hprebn - hprebn.mean(0, keepdim=True)) / torch.sqrt(hprebn.var(0, keepdim=True, unbiased=True) + 1e-5) + bnbias\n",
    "print('max diff:', (hpreact_fast - hpreact).abs().max().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hprebn          | exact: False | approximate: True  | maxdiff: 9.313225746154785e-10\n"
     ]
    }
   ],
   "source": [
    "# backward pass\n",
    "\n",
    "# before we had:\n",
    "# dbnraw = bngain * dhpreact\n",
    "# dbndiff = bnvar_inv * dbnraw\n",
    "# dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True)\n",
    "# dbnvar = (-0.5*(bnvar + 1e-5)**-1.5) * dbnvar_inv\n",
    "# dbndiff2 = (1.0/(n-1))*torch.ones_like(bndiff2) * dbnvar\n",
    "# dbndiff += (2*bndiff) * dbndiff2\n",
    "# dhprebn = dbndiff.clone()\n",
    "# dbnmeani = (-dbndiff).sum(0)\n",
    "# dhprebn += 1.0/n * (torch.ones_like(hprebn) * dbnmeani)\n",
    "\n",
    "# calculate dhprebn given dhpreact (i.e. backprop through the batchnorm)\n",
    "# (you'll also need to use some of the variables from the forward pass up above)\n",
    "\n",
    "dhprebn = bngain*bnvar_inv/n * (n*dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))\n",
    "\n",
    "cmp('hprebn', dhprebn, hprebn) # I can only get approximate to be true, my maxdiff is 9e-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changed hyper-parameters to run fewer optimization steps on local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12297\n",
      "      0/  10000: 3.7911\n",
      "   1000/  10000: 2.1045\n",
      "   2000/  10000: 2.1934\n",
      "   3000/  10000: 2.1842\n",
      "   4000/  10000: 2.3998\n",
      "   5000/  10000: 2.0411\n",
      "   6000/  10000: 2.2369\n",
      "   7000/  10000: 2.1026\n",
      "   8000/  10000: 2.0765\n",
      "   9000/  10000: 1.9834\n"
     ]
    }
   ],
   "source": [
    "# Exercise 4: putting it all together!\n",
    "# Train the MLP neural net with your own backward pass\n",
    "\n",
    "# init\n",
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 200 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "C  = torch.randn((vocab_size, n_embd),            generator=g)\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)\n",
    "b1 = torch.randn(n_hidden,                        generator=g) * 0.1\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size),          generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size,                      generator=g) * 0.1\n",
    "# BatchNorm parameters\n",
    "bngain = torch.randn((1, n_hidden))*0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden))*0.1\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "  p.requires_grad = True\n",
    "\n",
    "# same optimization as last time.\n",
    "max_steps = 10000\n",
    "batch_size = 128\n",
    "n = batch_size # convenience\n",
    "lossi = []\n",
    "\n",
    "# use this context manager for efficiency once your backward pass is written (TODO)\n",
    "with torch.no_grad():\n",
    "\n",
    "  # kick off optimization\n",
    "  for i in range(max_steps):\n",
    "\n",
    "    # minibatch construct\n",
    "    ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "    Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
    "\n",
    "    # forward pass\n",
    "    emb = C[Xb] # embed the characters into vectors\n",
    "    embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "    # Linear layer\n",
    "    hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "    # BatchNorm layer\n",
    "    # -------------------------------------------------------------\n",
    "    bnmean = hprebn.mean(0, keepdim=True)\n",
    "    bnvar = hprebn.var(0, keepdim=True, unbiased=True)\n",
    "    bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "    bnraw = (hprebn - bnmean) * bnvar_inv\n",
    "    hpreact = bngain * bnraw + bnbias\n",
    "    # -------------------------------------------------------------\n",
    "    # Non-linearity\n",
    "    h = torch.tanh(hpreact) # hidden layer\n",
    "    logits = h @ W2 + b2 # output layer\n",
    "    loss = F.cross_entropy(logits, Yb) # loss function\n",
    "\n",
    "    # backward pass\n",
    "    for p in parameters:\n",
    "      p.grad = None\n",
    "    #loss.backward() # use this for correctness comparisons, delete it later!\n",
    "\n",
    "    # manual backprop! #swole_doge_meme\n",
    "    # -----------------\n",
    "    dlogits = F.softmax(logits, 1)\n",
    "    dlogits[range(n), Yb] -= 1\n",
    "    dlogits /= n\n",
    "    # 2nd layer backprop\n",
    "    dh = dlogits @ W2.T\n",
    "    dW2 = h.T @ dlogits\n",
    "    db2 = dlogits.sum(0)\n",
    "    # tanh\n",
    "    dhpreact = (1.0 - h**2) * dh\n",
    "    # batchnorm backprop\n",
    "    dbngain = (bnraw * dhpreact).sum(0, keepdim=True)\n",
    "    dbnbias = dhpreact.sum(0, keepdim=True)\n",
    "    dhprebn = bngain*bnvar_inv/n * (n*dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))\n",
    "    # 1st layer\n",
    "    dembcat = dhprebn @ W1.T\n",
    "    dW1 = embcat.T @ dhprebn\n",
    "    db1 = dhprebn.sum(0)\n",
    "    # embedding\n",
    "    demb = dembcat.view(emb.shape)\n",
    "    dC = torch.zeros_like(C)\n",
    "    for k in range(Xb.shape[0]):\n",
    "      for j in range(Xb.shape[1]):\n",
    "        ix = Xb[k,j]\n",
    "        dC[ix] += demb[k,j]\n",
    "    grads = [dC, dW1, db1, dW2, db2, dbngain, dbnbias]\n",
    "    # -----------------\n",
    "\n",
    "    # update\n",
    "    lr = 0.5 if i < 6000 else 0.1 # step learning rate decay\n",
    "    for p, grad in zip(parameters, grads):\n",
    "      #p.data += -lr * p.grad # old way of cheems doge (using PyTorch grad from .backward())\n",
    "      p.data += -lr * grad # new way of swole doge TODO: enable\n",
    "\n",
    "    # track stats\n",
    "    if i % 1000 == 0: # print every once in a while\n",
    "      print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "    lossi.append(loss.log10().item())\n",
    "\n",
    "  #   if i >= 100: # TODO: delete early breaking when you're ready to train the full net\n",
    "  #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful for checking your gradients\n",
    "# for p,g in zip(parameters, grads):\n",
    "#   cmp(str(tuple(p.shape)), g, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calibrate the batch norm at the end of training\n",
    "\n",
    "with torch.no_grad():\n",
    "  # pass the training set through\n",
    "  emb = C[Xtr]\n",
    "  embcat = emb.view(emb.shape[0], -1)\n",
    "  hpreact = embcat @ W1 + b1\n",
    "  # measure the mean/std over the entire training set\n",
    "  bnmean = hpreact.mean(0, keepdim=True)\n",
    "  bnvar = hpreact.var(0, keepdim=True, unbiased=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 2.1284337043762207\n",
      "val 2.151392936706543\n"
     ]
    }
   ],
   "source": [
    "# evaluate train and val loss\n",
    "\n",
    "@torch.no_grad() # this decorator disables gradient tracking\n",
    "def split_loss(split):\n",
    "  x,y = {\n",
    "    'train': (Xtr, Ytr),\n",
    "    'val': (Xdev, Ydev),\n",
    "    'test': (Xte, Yte),\n",
    "  }[split]\n",
    "  emb = C[x] # (N, block_size, n_embd)\n",
    "  embcat = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
    "  hpreact = embcat @ W1 + b1\n",
    "  hpreact = bngain * (hpreact - bnmean) * (bnvar + 1e-5)**-0.5 + bnbias\n",
    "  h = torch.tanh(hpreact) # (N, n_hidden)\n",
    "  logits = h @ W2 + b2 # (N, vocab_size)\n",
    "  loss = F.cross_entropy(logits, y)\n",
    "  print(split, loss.item())\n",
    "\n",
    "split_loss('train')\n",
    "split_loss('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mora.\n",
      "kmyah.\n",
      "see.\n",
      "med.\n",
      "ryla.\n",
      "remmrucendraegradelynnelin.\n",
      "shi.\n",
      "jen.\n",
      "eden.\n",
      "estanaraelynn.\n",
      "houra.\n",
      "noshubergihiriel.\n",
      "kinde.\n",
      "jelinnetton.\n",
      "kuba.\n",
      "geda.\n",
      "jamell.\n",
      "els.\n",
      "kaysh.\n",
      "samyah.\n"
     ]
    }
   ],
   "source": [
    "# sample from the model\n",
    "g = torch.Generator().manual_seed(2147483647 + 10)\n",
    "\n",
    "for _ in range(20):\n",
    "    \n",
    "    out = []\n",
    "    context = [0] * block_size # initialize with all ...\n",
    "    while True:\n",
    "      # ------------\n",
    "      # forward pass:\n",
    "      # Embedding\n",
    "      emb = C[torch.tensor([context])] # (1,block_size,d)      \n",
    "      embcat = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
    "      hpreact = embcat @ W1 + b1\n",
    "      hpreact = bngain * (hpreact - bnmean) * (bnvar + 1e-5)**-0.5 + bnbias\n",
    "      h = torch.tanh(hpreact) # (N, n_hidden)\n",
    "      logits = h @ W2 + b2 # (N, vocab_size)\n",
    "      # ------------\n",
    "      # Sample\n",
    "      probs = F.softmax(logits, dim=1)\n",
    "      ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
    "      context = context[1:] + [ix]\n",
    "      out.append(ix)\n",
    "      if ix == 0:\n",
    "        break\n",
    "    \n",
    "    print(''.join(itos[i] for i in out))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zero2hero",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
